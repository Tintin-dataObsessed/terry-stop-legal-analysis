# terry-stop-legal-analysis overview
Analysis of the landmark 1968 U.S. Supreme Court case Terry v. Ohio, which established the legal standard of "reasonable suspicion" and introduced the concept of Terry Stops.

The aim is to analyse the Police Department data to build a model that predicts whether an arrest happened after a Terry Stop, using details like whether a weapon was present and the time of the stop. This is a binary classification task, which means to arrest or not arrest.

# Background
The Fourth Amendment is meant to protect people from being searched or arrested without a good reason. It says that the government can’t do “unreasonable searches and seizures,” which means police need a solid reason—and often a warrant—before they can take you into custody. Reasonable suspicion is a concept that came out of the Terry v. Ohio case. It gives police the right to stop and briefly question someone if they think something suspicious is happening, even if they don’t have enough evidence to arrest them yet.

# Legal and Data Understanding
The problem is Terry v. Ohio shifted policing by allowing officers to stop people based on reasonable suspicion instead of stronger evidence. This helped police act faster in risky situations but also raised concerns about over-policing and potential bias in how these stops are used.

This project aims to:

-Identify factors influencing arrest likelihood

-Explore patterns and biases in Terry Stops

-Showcase the application of supervised learning in a legal context

Explain your stakeholder audience and dataset choice here
Modeling
Evaluation
Conclusion